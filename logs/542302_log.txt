注：一维数据log
Namespace(M=2, batch_size=100, block_len=100, channel='awgn', code_rate_k=1, code_rate_n=3, dropout=0.5, enc1=7, enc2=5, enc_clipping='both', enc_grad_limit=0.01, enc_quantize_level=2, enc_value_limit=1.0, feedback=7, init_nw_weight='./models/torch_model_decoder_036718.pt', is_parallel=0, is_train=True, kernel_size=3, lr=0.0001, momentum=0.9, no_cuda=False, num_block=7000, num_epoch=200, num_iteration=6, num_layer=14, num_test_block=3000, optimizer='adam', precompute_norm_stats=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, rec_quantize=False, rec_quantize_level=2, rec_quantize_limit=1.0, snr_points=9, snr_test_end=15.0, snr_test_start=15.0, test_channel_mode='block_norm', test_ratio=1, train_channel_high=15.0, train_channel_low=15.0, train_channel_mode='block_norm')
[Convolutional Code Codec] Encoder M  [2]  Generator Matrix  [[7 5]]  Feedback  7
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 100, 1)       0                                            
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 100, 1)       4           input_1[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 100, 1)       0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 100, 64)      256         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 100, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 100, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 100, 64)      12352       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 100, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 100, 64)      0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 100, 64)      12352       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 100, 64)      256         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 64)      0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 100, 64)      12352       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 100, 64)      256         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 100, 64)      0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 100, 64)      12352       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 100, 64)      256         conv1d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 64)      0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 100, 64)      12352       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 100, 64)      256         conv1d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 100, 64)      0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 100, 64)      12352       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 100, 64)      256         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 100, 64)      0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 100, 64)      12352       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 100, 64)      256         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 100, 64)      0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 100, 64)      12352       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 100, 64)      256         conv1d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 100, 64)      0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_11 (Conv1D)              (None, 100, 64)      12352       activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 100, 64)      256         conv1d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 100, 64)      0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv1d_12 (Conv1D)              (None, 100, 64)      12352       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 100, 64)      256         conv1d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 100, 64)      0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv1d_13 (Conv1D)              (None, 100, 64)      12352       activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 100, 64)      256         conv1d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 100, 64)      0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv1d_14 (Conv1D)              (None, 100, 64)      12352       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 100, 64)      256         conv1d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 100, 64)      0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv1d_15 (Conv1D)              (None, 100, 64)      12352       activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 100, 64)      256         conv1d_15[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 100, 64)      0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv1d_16 (Conv1D)              (None, 100, 1)       193         activation_15[0][0]              
__________________________________________________________________________________________________
subtract_1 (Subtract)           (None, 100, 1)       0           input_1[0][0]                    
                                                                 conv1d_16[0][0]                  
==================================================================================================
Total params: 164,613
Trainable params: 162,821
Non-trainable params: 1,792
__________________________________________________________________________________________________
None
Train on 7000 samples, validate on 3000 samples
Epoch 1/200
 - 15s - loss: 0.2983 - errors: 0.3061 - val_loss: 0.5718 - val_errors: 0.3673
Epoch 2/200
 - 4s - loss: 0.0729 - errors: 0.0624 - val_loss: 0.1587 - val_errors: 0.1489
Epoch 3/200
 - 4s - loss: 0.0427 - errors: 0.0181 - val_loss: 0.0670 - val_errors: 0.0534
Epoch 4/200
 - 4s - loss: 0.0365 - errors: 0.0105 - val_loss: 0.0445 - val_errors: 0.0212
Epoch 5/200
 - 4s - loss: 0.0340 - errors: 0.0078 - val_loss: 0.0377 - val_errors: 0.0122
Epoch 6/200
 - 4s - loss: 0.0325 - errors: 0.0065 - val_loss: 0.0344 - val_errors: 0.0086
Epoch 7/200
 - 4s - loss: 0.0316 - errors: 0.0058 - val_loss: 0.0327 - val_errors: 0.0071
Epoch 8/200
 - 4s - loss: 0.0309 - errors: 0.0055 - val_loss: 0.0316 - val_errors: 0.0062
Epoch 9/200
 - 4s - loss: 0.0304 - errors: 0.0051 - val_loss: 0.0309 - val_errors: 0.0056
Epoch 10/200
 - 4s - loss: 0.0299 - errors: 0.0048 - val_loss: 0.0303 - val_errors: 0.0052

Epoch 00010: saving model to ./tmp/weights_10-0.03.h5
Epoch 11/200
 - 4s - loss: 0.0295 - errors: 0.0046 - val_loss: 0.0298 - val_errors: 0.0050
Epoch 12/200
 - 4s - loss: 0.0291 - errors: 0.0045 - val_loss: 0.0294 - val_errors: 0.0047
Epoch 13/200
 - 4s - loss: 0.0287 - errors: 0.0044 - val_loss: 0.0290 - val_errors: 0.0047
Epoch 14/200
 - 4s - loss: 0.0284 - errors: 0.0043 - val_loss: 0.0286 - val_errors: 0.0046
Epoch 15/200
 - 5s - loss: 0.0280 - errors: 0.0041 - val_loss: 0.0282 - val_errors: 0.0045
Epoch 16/200
 - 5s - loss: 0.0276 - errors: 0.0041 - val_loss: 0.0278 - val_errors: 0.0044
Epoch 17/200
 - 5s - loss: 0.0272 - errors: 0.0040 - val_loss: 0.0274 - val_errors: 0.0044
Epoch 18/200
 - 5s - loss: 0.0267 - errors: 0.0040 - val_loss: 0.0270 - val_errors: 0.0043
Epoch 19/200
 - 5s - loss: 0.0263 - errors: 0.0039 - val_loss: 0.0265 - val_errors: 0.0043
Epoch 20/200
 - 5s - loss: 0.0258 - errors: 0.0039 - val_loss: 0.0260 - val_errors: 0.0042

Epoch 00020: saving model to ./tmp/weights_20-0.03.h5
Epoch 21/200
 - 5s - loss: 0.0253 - errors: 0.0039 - val_loss: 0.0254 - val_errors: 0.0042
Epoch 22/200
 - 5s - loss: 0.0247 - errors: 0.0039 - val_loss: 0.0248 - val_errors: 0.0042
Epoch 23/200
 - 5s - loss: 0.0241 - errors: 0.0040 - val_loss: 0.0243 - val_errors: 0.0043
Epoch 24/200
 - 5s - loss: 0.0234 - errors: 0.0039 - val_loss: 0.0236 - val_errors: 0.0042
Epoch 25/200
 - 5s - loss: 0.0227 - errors: 0.0040 - val_loss: 0.0229 - val_errors: 0.0043
Epoch 26/200
 - 5s - loss: 0.0220 - errors: 0.0040 - val_loss: 0.0222 - val_errors: 0.0043
Epoch 27/200
 - 5s - loss: 0.0212 - errors: 0.0040 - val_loss: 0.0213 - val_errors: 0.0043
Epoch 28/200
 - 5s - loss: 0.0204 - errors: 0.0040 - val_loss: 0.0205 - val_errors: 0.0044
Epoch 29/200
 - 5s - loss: 0.0195 - errors: 0.0040 - val_loss: 0.0196 - val_errors: 0.0044
Epoch 30/200
 - 5s - loss: 0.0186 - errors: 0.0041 - val_loss: 0.0188 - val_errors: 0.0043

Epoch 00030: saving model to ./tmp/weights_30-0.02.h5
Epoch 31/200
 - 6s - loss: 0.0177 - errors: 0.0040 - val_loss: 0.0179 - val_errors: 0.0043
Epoch 32/200
 - 6s - loss: 0.0168 - errors: 0.0040 - val_loss: 0.0170 - val_errors: 0.0042
Epoch 33/200
 - 6s - loss: 0.0160 - errors: 0.0040 - val_loss: 0.0161 - val_errors: 0.0042
Epoch 34/200
 - 6s - loss: 0.0151 - errors: 0.0039 - val_loss: 0.0154 - val_errors: 0.0041
Epoch 35/200
 - 6s - loss: 0.0144 - errors: 0.0038 - val_loss: 0.0146 - val_errors: 0.0040
Epoch 36/200
 - 6s - loss: 0.0136 - errors: 0.0037 - val_loss: 0.0138 - val_errors: 0.0040
Epoch 37/200
 - 6s - loss: 0.0129 - errors: 0.0037 - val_loss: 0.0132 - val_errors: 0.0038
Epoch 38/200
 - 7s - loss: 0.0123 - errors: 0.0037 - val_loss: 0.0126 - val_errors: 0.0038
Epoch 39/200
 - 8s - loss: 0.0116 - errors: 0.0036 - val_loss: 0.0120 - val_errors: 0.0038
Epoch 40/200
 - 7s - loss: 0.0111 - errors: 0.0036 - val_loss: 0.0113 - val_errors: 0.0038

Epoch 00040: saving model to ./tmp/weights_40-0.01.h5
Epoch 41/200
 - 7s - loss: 0.0106 - errors: 0.0035 - val_loss: 0.0109 - val_errors: 0.0037
Epoch 42/200
 - 7s - loss: 0.0101 - errors: 0.0034 - val_loss: 0.0104 - val_errors: 0.0037
Epoch 43/200
 - 7s - loss: 0.0096 - errors: 0.0034 - val_loss: 0.0100 - val_errors: 0.0036
Epoch 44/200
 - 7s - loss: 0.0092 - errors: 0.0034 - val_loss: 0.0095 - val_errors: 0.0036
Epoch 45/200
 - 8s - loss: 0.0088 - errors: 0.0033 - val_loss: 0.0092 - val_errors: 0.0035
Epoch 46/200
 - 8s - loss: 0.0085 - errors: 0.0033 - val_loss: 0.0088 - val_errors: 0.0035
Epoch 47/200
 - 8s - loss: 0.0082 - errors: 0.0032 - val_loss: 0.0085 - val_errors: 0.0034
Epoch 48/200
 - 9s - loss: 0.0079 - errors: 0.0032 - val_loss: 0.0082 - val_errors: 0.0034
Epoch 49/200
 - 8s - loss: 0.0076 - errors: 0.0032 - val_loss: 0.0079 - val_errors: 0.0034
Epoch 50/200
 - 8s - loss: 0.0073 - errors: 0.0031 - val_loss: 0.0077 - val_errors: 0.0033

Epoch 00050: saving model to ./tmp/weights_50-0.01.h5
Epoch 51/200
 - 7s - loss: 0.0070 - errors: 0.0031 - val_loss: 0.0073 - val_errors: 0.0033
Epoch 52/200
 - 10s - loss: 0.0068 - errors: 0.0031 - val_loss: 0.0072 - val_errors: 0.0032
Epoch 53/200
 - 9s - loss: 0.0066 - errors: 0.0031 - val_loss: 0.0070 - val_errors: 0.0032
Epoch 54/200
 - 8s - loss: 0.0064 - errors: 0.0030 - val_loss: 0.0067 - val_errors: 0.0032
Epoch 55/200
 - 8s - loss: 0.0062 - errors: 0.0030 - val_loss: 0.0065 - val_errors: 0.0032
Epoch 56/200
 - 8s - loss: 0.0060 - errors: 0.0030 - val_loss: 0.0064 - val_errors: 0.0032
Epoch 57/200
 - 11s - loss: 0.0058 - errors: 0.0029 - val_loss: 0.0061 - val_errors: 0.0031
Epoch 58/200
 - 11s - loss: 0.0057 - errors: 0.0029 - val_loss: 0.0060 - val_errors: 0.0031
Epoch 59/200
 - 10s - loss: 0.0055 - errors: 0.0029 - val_loss: 0.0058 - val_errors: 0.0031
Epoch 60/200
 - 8s - loss: 0.0054 - errors: 0.0028 - val_loss: 0.0057 - val_errors: 0.0031

Epoch 00060: saving model to ./tmp/weights_60-0.01.h5
Epoch 61/200
 - 11s - loss: 0.0052 - errors: 0.0028 - val_loss: 0.0055 - val_errors: 0.0030
Epoch 62/200
 - 10s - loss: 0.0051 - errors: 0.0028 - val_loss: 0.0054 - val_errors: 0.0030
Epoch 63/200
 - 10s - loss: 0.0050 - errors: 0.0027 - val_loss: 0.0052 - val_errors: 0.0030
Epoch 64/200
 - 9s - loss: 0.0049 - errors: 0.0028 - val_loss: 0.0052 - val_errors: 0.0030
Epoch 65/200
 - 9s - loss: 0.0048 - errors: 0.0027 - val_loss: 0.0050 - val_errors: 0.0030
Epoch 66/200
 - 11s - loss: 0.0047 - errors: 0.0027 - val_loss: 0.0049 - val_errors: 0.0030
Epoch 67/200
 - 11s - loss: 0.0046 - errors: 0.0027 - val_loss: 0.0049 - val_errors: 0.0030
Epoch 68/200
 - 11s - loss: 0.0045 - errors: 0.0027 - val_loss: 0.0048 - val_errors: 0.0030
Epoch 69/200
 - 11s - loss: 0.0044 - errors: 0.0027 - val_loss: 0.0047 - val_errors: 0.0030
Epoch 70/200
 - 11s - loss: 0.0043 - errors: 0.0026 - val_loss: 0.0047 - val_errors: 0.0030

Epoch 00070: saving model to ./tmp/weights_70-0.00.h5
Epoch 71/200
 - 11s - loss: 0.0043 - errors: 0.0026 - val_loss: 0.0045 - val_errors: 0.0029
Epoch 72/200
 - 11s - loss: 0.0042 - errors: 0.0026 - val_loss: 0.0045 - val_errors: 0.0029
Epoch 73/200
 - 11s - loss: 0.0041 - errors: 0.0026 - val_loss: 0.0044 - val_errors: 0.0029
Epoch 74/200
 - 11s - loss: 0.0041 - errors: 0.0026 - val_loss: 0.0044 - val_errors: 0.0029
Epoch 75/200
 - 11s - loss: 0.0040 - errors: 0.0026 - val_loss: 0.0043 - val_errors: 0.0029
Epoch 76/200
 - 11s - loss: 0.0039 - errors: 0.0026 - val_loss: 0.0042 - val_errors: 0.0029
Epoch 77/200
 - 11s - loss: 0.0039 - errors: 0.0025 - val_loss: 0.0042 - val_errors: 0.0029
Epoch 78/200
 - 11s - loss: 0.0038 - errors: 0.0025 - val_loss: 0.0041 - val_errors: 0.0028
Epoch 79/200
 - 11s - loss: 0.0038 - errors: 0.0025 - val_loss: 0.0041 - val_errors: 0.0029
Epoch 80/200
 - 11s - loss: 0.0037 - errors: 0.0025 - val_loss: 0.0040 - val_errors: 0.0028

Epoch 00080: saving model to ./tmp/weights_80-0.00.h5
Epoch 81/200
 - 11s - loss: 0.0037 - errors: 0.0025 - val_loss: 0.0040 - val_errors: 0.0028
Epoch 82/200
 - 11s - loss: 0.0036 - errors: 0.0025 - val_loss: 0.0039 - val_errors: 0.0028
Epoch 83/200
 - 11s - loss: 0.0036 - errors: 0.0025 - val_loss: 0.0039 - val_errors: 0.0028
Epoch 84/200
 - 11s - loss: 0.0036 - errors: 0.0024 - val_loss: 0.0039 - val_errors: 0.0028
Epoch 85/200
 - 11s - loss: 0.0035 - errors: 0.0024 - val_loss: 0.0038 - val_errors: 0.0028
Epoch 86/200
 - 11s - loss: 0.0035 - errors: 0.0024 - val_loss: 0.0037 - val_errors: 0.0028
Epoch 87/200
 - 11s - loss: 0.0034 - errors: 0.0024 - val_loss: 0.0038 - val_errors: 0.0028
Epoch 88/200
 - 18s - loss: 0.0034 - errors: 0.0024 - val_loss: 0.0037 - val_errors: 0.0028
Epoch 89/200
 - 14s - loss: 0.0034 - errors: 0.0024 - val_loss: 0.0037 - val_errors: 0.0028
Epoch 90/200
 - 12s - loss: 0.0033 - errors: 0.0024 - val_loss: 0.0037 - val_errors: 0.0028

Epoch 00090: saving model to ./tmp/weights_90-0.00.h5
Epoch 91/200
 - 12s - loss: 0.0033 - errors: 0.0024 - val_loss: 0.0036 - val_errors: 0.0028
Epoch 92/200
 - 11s - loss: 0.0033 - errors: 0.0023 - val_loss: 0.0036 - val_errors: 0.0028
Epoch 93/200
 - 11s - loss: 0.0032 - errors: 0.0023 - val_loss: 0.0036 - val_errors: 0.0028
Epoch 94/200
 - 11s - loss: 0.0032 - errors: 0.0023 - val_loss: 0.0035 - val_errors: 0.0028
Epoch 95/200
 - 11s - loss: 0.0032 - errors: 0.0023 - val_loss: 0.0036 - val_errors: 0.0028
Epoch 96/200
 - 11s - loss: 0.0032 - errors: 0.0023 - val_loss: 0.0035 - val_errors: 0.0028
Epoch 97/200
 - 11s - loss: 0.0032 - errors: 0.0023 - val_loss: 0.0035 - val_errors: 0.0028
Epoch 98/200
 - 11s - loss: 0.0031 - errors: 0.0023 - val_loss: 0.0035 - val_errors: 0.0028
Epoch 99/200
 - 19s - loss: 0.0031 - errors: 0.0023 - val_loss: 0.0034 - val_errors: 0.0028
Epoch 100/200
 - 15s - loss: 0.0031 - errors: 0.0023 - val_loss: 0.0034 - val_errors: 0.0028

Epoch 00100: saving model to ./tmp/weights_100-0.00.h5
Epoch 101/200
 - 14s - loss: 0.0030 - errors: 0.0022 - val_loss: 0.0034 - val_errors: 0.0028
Epoch 102/200
 - 11s - loss: 0.0030 - errors: 0.0022 - val_loss: 0.0035 - val_errors: 0.0028
Epoch 103/200
 - 11s - loss: 0.0030 - errors: 0.0022 - val_loss: 0.0035 - val_errors: 0.0028
Epoch 104/200
 - 11s - loss: 0.0030 - errors: 0.0022 - val_loss: 0.0034 - val_errors: 0.0028
Epoch 105/200
 - 11s - loss: 0.0030 - errors: 0.0022 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 106/200
 - 11s - loss: 0.0029 - errors: 0.0022 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 107/200
 - 18s - loss: 0.0029 - errors: 0.0021 - val_loss: 0.0033 - val_errors: 0.0027
Epoch 108/200
 - 18s - loss: 0.0029 - errors: 0.0022 - val_loss: 0.0034 - val_errors: 0.0028
Epoch 109/200
 - 16s - loss: 0.0029 - errors: 0.0022 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 110/200
 - 17s - loss: 0.0029 - errors: 0.0022 - val_loss: 0.0034 - val_errors: 0.0028

Epoch 00110: saving model to ./tmp/weights_110-0.00.h5
Epoch 111/200
 - 16s - loss: 0.0029 - errors: 0.0021 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 112/200
 - 13s - loss: 0.0028 - errors: 0.0021 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 113/200
 - 13s - loss: 0.0028 - errors: 0.0021 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 114/200
 - 19s - loss: 0.0028 - errors: 0.0020 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 115/200
 - 15s - loss: 0.0028 - errors: 0.0021 - val_loss: 0.0034 - val_errors: 0.0028
Epoch 116/200
 - 17s - loss: 0.0027 - errors: 0.0020 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 117/200
 - 11s - loss: 0.0027 - errors: 0.0021 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 118/200
 - 15s - loss: 0.0027 - errors: 0.0021 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 119/200
 - 19s - loss: 0.0027 - errors: 0.0020 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 120/200
 - 16s - loss: 0.0027 - errors: 0.0020 - val_loss: 0.0032 - val_errors: 0.0028

Epoch 00120: saving model to ./tmp/weights_120-0.00.h5
Epoch 121/200
 - 16s - loss: 0.0027 - errors: 0.0020 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 122/200
 - 11s - loss: 0.0027 - errors: 0.0020 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 123/200
 - 11s - loss: 0.0026 - errors: 0.0019 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 124/200
 - 16s - loss: 0.0026 - errors: 0.0019 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 125/200
 - 19s - loss: 0.0026 - errors: 0.0020 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 126/200
 - 18s - loss: 0.0026 - errors: 0.0019 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 127/200
 - 16s - loss: 0.0026 - errors: 0.0019 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 128/200
 - 18s - loss: 0.0026 - errors: 0.0019 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 129/200
 - 18s - loss: 0.0025 - errors: 0.0018 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 130/200
 - 17s - loss: 0.0025 - errors: 0.0018 - val_loss: 0.0032 - val_errors: 0.0028

Epoch 00130: saving model to ./tmp/weights_130-0.00.h5
Epoch 131/200
 - 17s - loss: 0.0025 - errors: 0.0018 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 132/200
 - 14s - loss: 0.0025 - errors: 0.0018 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 133/200
 - 11s - loss: 0.0025 - errors: 0.0018 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 134/200
 - 13s - loss: 0.0025 - errors: 0.0018 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 135/200
 - 19s - loss: 0.0025 - errors: 0.0018 - val_loss: 0.0032 - val_errors: 0.0029
Epoch 136/200
 - 19s - loss: 0.0024 - errors: 0.0017 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 137/200
 - 19s - loss: 0.0024 - errors: 0.0017 - val_loss: 0.0034 - val_errors: 0.0029
Epoch 138/200
 - 19s - loss: 0.0024 - errors: 0.0017 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 139/200
 - 19s - loss: 0.0024 - errors: 0.0017 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 140/200
 - 18s - loss: 0.0024 - errors: 0.0016 - val_loss: 0.0033 - val_errors: 0.0028

Epoch 00140: saving model to ./tmp/weights_140-0.00.h5
Epoch 141/200
 - 19s - loss: 0.0024 - errors: 0.0016 - val_loss: 0.0033 - val_errors: 0.0028
Epoch 142/200
 - 19s - loss: 0.0023 - errors: 0.0016 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 143/200
 - 18s - loss: 0.0023 - errors: 0.0015 - val_loss: 0.0032 - val_errors: 0.0028
Epoch 144/200
 - 19s - loss: 0.0023 - errors: 0.0016 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 145/200
 - 19s - loss: 0.0023 - errors: 0.0016 - val_loss: 0.0032 - val_errors: 0.0029
Epoch 146/200
 - 19s - loss: 0.0023 - errors: 0.0015 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 147/200
 - 19s - loss: 0.0023 - errors: 0.0015 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 148/200
 - 19s - loss: 0.0022 - errors: 0.0015 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 149/200
 - 19s - loss: 0.0022 - errors: 0.0015 - val_loss: 0.0034 - val_errors: 0.0029
Epoch 150/200
 - 19s - loss: 0.0022 - errors: 0.0015 - val_loss: 0.0032 - val_errors: 0.0029

Epoch 00150: saving model to ./tmp/weights_150-0.00.h5
Epoch 151/200
 - 19s - loss: 0.0022 - errors: 0.0014 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 152/200
 - 19s - loss: 0.0022 - errors: 0.0014 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 153/200
 - 19s - loss: 0.0022 - errors: 0.0014 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 154/200
 - 19s - loss: 0.0021 - errors: 0.0014 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 155/200
 - 19s - loss: 0.0021 - errors: 0.0014 - val_loss: 0.0033 - val_errors: 0.0029
Epoch 156/200
 - 19s - loss: 0.0021 - errors: 0.0014 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 157/200
 - 19s - loss: 0.0021 - errors: 0.0013 - val_loss: 0.0033 - val_errors: 0.0030
Epoch 158/200
 - 19s - loss: 0.0021 - errors: 0.0014 - val_loss: 0.0034 - val_errors: 0.0029
Epoch 159/200
 - 19s - loss: 0.0022 - errors: 0.0014 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 160/200
 - 19s - loss: 0.0021 - errors: 0.0013 - val_loss: 0.0033 - val_errors: 0.0029

Epoch 00160: saving model to ./tmp/weights_160-0.00.h5
Epoch 161/200
 - 19s - loss: 0.0020 - errors: 0.0013 - val_loss: 0.0033 - val_errors: 0.0030
Epoch 162/200
 - 19s - loss: 0.0020 - errors: 0.0013 - val_loss: 0.0034 - val_errors: 0.0029
Epoch 163/200
 - 19s - loss: 0.0020 - errors: 0.0013 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 164/200
 - 19s - loss: 0.0020 - errors: 0.0013 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 165/200
 - 19s - loss: 0.0020 - errors: 0.0012 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 166/200
 - 19s - loss: 0.0020 - errors: 0.0013 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 167/200
 - 19s - loss: 0.0020 - errors: 0.0012 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 168/200
 - 19s - loss: 0.0020 - errors: 0.0012 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 169/200
 - 19s - loss: 0.0020 - errors: 0.0012 - val_loss: 0.0035 - val_errors: 0.0030
Epoch 170/200
 - 19s - loss: 0.0020 - errors: 0.0012 - val_loss: 0.0034 - val_errors: 0.0030

Epoch 00170: saving model to ./tmp/weights_170-0.00.h5
Epoch 171/200
 - 16s - loss: 0.0019 - errors: 0.0011 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 172/200
 - 19s - loss: 0.0019 - errors: 0.0011 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 173/200
 - 19s - loss: 0.0019 - errors: 0.0011 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 174/200
 - 19s - loss: 0.0019 - errors: 0.0011 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 175/200
 - 19s - loss: 0.0020 - errors: 0.0013 - val_loss: 0.0035 - val_errors: 0.0030
Epoch 176/200
 - 19s - loss: 0.0020 - errors: 0.0013 - val_loss: 0.0034 - val_errors: 0.0031
Epoch 177/200
 - 19s - loss: 0.0019 - errors: 0.0012 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 178/200
 - 19s - loss: 0.0019 - errors: 0.0011 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 179/200
 - 19s - loss: 0.0019 - errors: 0.0011 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 180/200
 - 19s - loss: 0.0018 - errors: 0.0011 - val_loss: 0.0035 - val_errors: 0.0031

Epoch 00180: saving model to ./tmp/weights_180-0.00.h5
Epoch 181/200
 - 19s - loss: 0.0018 - errors: 0.0011 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 182/200
 - 19s - loss: 0.0018 - errors: 0.0011 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 183/200
 - 19s - loss: 0.0019 - errors: 0.0011 - val_loss: 0.0034 - val_errors: 0.0030
Epoch 184/200
 - 19s - loss: 0.0018 - errors: 0.0011 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 185/200
 - 19s - loss: 0.0018 - errors: 0.0010 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 186/200
 - 19s - loss: 0.0018 - errors: 0.0010 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 187/200
 - 19s - loss: 0.0018 - errors: 0.0010 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 188/200
 - 19s - loss: 0.0018 - errors: 0.0011 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 189/200
 - 19s - loss: 0.0018 - errors: 0.0011 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 190/200
 - 19s - loss: 0.0018 - errors: 9.9143e-04 - val_loss: 0.0034 - val_errors: 0.0030

Epoch 00190: saving model to ./tmp/weights_190-0.00.h5
Epoch 191/200
 - 19s - loss: 0.0017 - errors: 9.6571e-04 - val_loss: 0.0034 - val_errors: 0.0031
Epoch 192/200
 - 19s - loss: 0.0018 - errors: 0.0010 - val_loss: 0.0035 - val_errors: 0.0030
Epoch 193/200
 - 19s - loss: 0.0017 - errors: 0.0010 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 194/200
 - 19s - loss: 0.0017 - errors: 9.7857e-04 - val_loss: 0.0035 - val_errors: 0.0030
Epoch 195/200
 - 19s - loss: 0.0017 - errors: 0.0010 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 196/200
 - 19s - loss: 0.0017 - errors: 9.3857e-04 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 197/200
 - 19s - loss: 0.0017 - errors: 9.7429e-04 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 198/200
 - 19s - loss: 0.0017 - errors: 9.3286e-04 - val_loss: 0.0035 - val_errors: 0.0030
Epoch 199/200
 - 19s - loss: 0.0017 - errors: 9.9000e-04 - val_loss: 0.0035 - val_errors: 0.0031
Epoch 200/200
 - 19s - loss: 0.0017 - errors: 9.6571e-04 - val_loss: 0.0035 - val_errors: 0.0031

Epoch 00200: saving model to ./tmp/weights_200-0.00.h5
Test set BER  0.001222857142857143
